{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Single Event Data from BL4A (multi-run mode)\n",
    "\n",
    "Version 1.3\n",
    "\n",
    "T. Charlton\n",
    "\n",
    "M.R. Fitzsimmons\n",
    "\n",
    "06.22.2020\n",
    "\n",
    "Added report of mean proton charge per spin state.\n",
    "\n",
    "Added dictionary functionality.\n",
    "\n",
    "06.28.2020 Add process variable for MAGH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This Notebook facilitates extraction of single event mode data from multiple runs\n",
    "This notebook needs to be run on analysis.sns.gov.  The files once written can be transferred to a local machine for further processing.\n",
    "\n",
    "    1) Sequentially loads many nexus event files.\n",
    "    2) Obtains per pulse proton charge for each event.\n",
    "    3) Removes proton flash.\n",
    "    4) Filter events based on polarization state.\n",
    "    5) Writes information in text and python binary files."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User provides list of run numbers to process. \n",
    "    1) User provides directory path to IPTS experiment.\n",
    "    2) User provides a list of run numbers in the array called \"run_numbers\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/SNS/users/mf3\n",
      "Current working directory: /SNS/users/mf3\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "%cd ~\n",
    "cwd_path = os.getcwd()\n",
    "print('Current working directory: %s'%cwd_path)\n",
    "\n",
    "#Example:\n",
    "#directory_path = cwd_path+r'/data/SNS/REF_M/IPTS-23100/' # user input\n",
    "#run_numbers = ['32400', '32398'] # user input\n",
    "\n",
    "#IPTS-23100\n",
    "#directory_path = cwd_path+r'/data/SNS/REF_M/IPTS-23100/' # user input\n",
    "#run_numbers = ['32400', '32398','32411','32412','32413','32414','32415','32416' ] # user input\n",
    "#run_numbers = ['32397'] # user input\n",
    "\n",
    "#IPTS-24314 Liz\n",
    "#directory_path = cwd_path+r'/data/SNS/REF_M/IPTS-24314/' # user input\n",
    "#run_numbers = ['34601','34605','34602','34603','34636','34637',\n",
    "#               '34638','34639','34668','34669','34670','34671','34672',\n",
    "#               '34644', '34645','34673' ] # user input\n",
    "\n",
    "#IPTS-24772 Misha\n",
    "directory_path = cwd_path+r'/data/SNS/REF_M/IPTS-24772/' # user input\n",
    "#run_numbers = ['35529','35530','35531','35532','35533','35534',\n",
    "#               '35535','35536','35537'] # user input\n",
    "#run_numbers = ['35538','35539','35540','35542','35543','35544','35545'] # user input\n",
    "run_numbers = ['35547','35548','35549','35550','35551','35552','35553'] # user input\n",
    "run_numbers = ['35558'] # user input\n",
    "#run_numbers = ['35554','35555','35556','35557','35558','35559'] # user input\n",
    "\n",
    "\n",
    "#IPTS-18520\n",
    "# Fails for this IPTS because the experiment was taken pre-epics transformation.\n",
    "\n",
    "#IPTS-21391\n",
    "#directory_path = cwd_path+r'/data/SNS/REF_M/IPTS-21391/' # user input\n",
    "#run_numbers = ['35096', '35097','35098' ] # user input\n",
    "#run_numbers = ['35000'] # user input 100G \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code to import required libraries (run in a Mantid compatible kernal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, math, getopt, glob, operator\n",
    "import numpy as np\n",
    "import numpy.ma as ma \n",
    "np.warnings.filterwarnings('ignore')\n",
    "import mantid\n",
    "from mantid.simpleapi import *\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import LogNorm\n",
    "from mantid import plots\n",
    "from datetime import datetime\n",
    "\n",
    "# Function to identify states of the two flippers for an event.\n",
    "def filter_cross_sections(ws):\n",
    "    \"\"\"\n",
    "        Filter events according to an aggregated state log.\n",
    "        :param str file_path: file to read\n",
    "\n",
    "        BL4A:SF:ICP:getDI\n",
    "\n",
    "        015 (0000 1111): SF1=OFF, SF2=OFF, SF1Veto=OFF, SF2Veto=OFF\n",
    "        047 (0010 1111): SF1=ON, SF2=OFF, SF1Veto=OFF, SF2Veto=OFF\n",
    "        031 (0001 1111): SF1=OFF, SF2=ON, SF1Veto=OFF, SF2Veto=OFF\n",
    "        063 (0011 1111): SF1=ON, SF2=ON, SF1Veto=OFF, SF2Veto=OFF\n",
    "        \n",
    "        From Mathieu Doucet.\n",
    "    \"\"\"\n",
    "    state_log = \"BL4A:SF:ICP:getDI\"\n",
    "    states = {'Off_Off': 15,\n",
    "              'On_Off': 47,\n",
    "              'Off_On': 31,\n",
    "              'On_On': 63}\n",
    "    cross_sections = []\n",
    "    cross_sections_dict = {}\n",
    "\n",
    "    for pol_state in states:\n",
    "        try:\n",
    "            _ws = FilterByLogValue(InputWorkspace=ws, \n",
    "                                   LogName=state_log, \n",
    "                                   TimeTolerance=0.1,\n",
    "                                   MinimumValue=states[pol_state],\n",
    "                                   MaximumValue=states[pol_state],\n",
    "                                   LogBoundary='Left',\n",
    "                                   OutputWorkspace='%s_%s'%(ws.getRunNumber(),\n",
    "                                                            pol_state))\n",
    "            _ws.getRun()['cross_section_id'] = pol_state\n",
    "            if _ws.getNumberEvents() > 0:\n",
    "                cross_sections.append(_ws)\n",
    "                cross_sections_dict[pol_state] =_ws\n",
    "        except:\n",
    "            mantid.logger.error(\"Could not filter %s: %s\"%(pol_state,\n",
    "                                                           sys.exc_info()[1]))\n",
    "\n",
    "    return cross_sections, cross_sections_dict\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main loop \n",
    "    1) Get data for the run.\n",
    "    2) Remove flash.\n",
    "    3) Separate into states.\n",
    "    4) Write files.\n",
    "    5) Repeat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: /SNS/users/mf3/data/SNS/REF_M/IPTS-24772/nexus/REF_M_35558.nxs.h5\n",
      "Mean proton charge: 23196382.09 (86088.99)\n",
      "Writing: /SNS/users/mf3/data/SNS/REF_M/IPTS-24772/shared/35558_events_Off_Off.txt\n",
      "Writing: /SNS/users/mf3/data/SNS/REF_M/IPTS-24772/shared/35558_events_log.txt\n"
     ]
    }
   ],
   "source": [
    "# All output files will be designated by run number, followed by:\n",
    "output_file_base = '_events'\n",
    "\n",
    "_nruns = len(run_numbers)\n",
    "\n",
    "for _runid in range(_nruns):\n",
    "    InputFile = directory_path+r'nexus/REF_M_'+run_numbers[_runid]+'.nxs.h5'\n",
    "    print('Processing: %s'%InputFile)\n",
    "    OutputFile = directory_path+r'shared/'+run_numbers[_runid]+output_file_base\n",
    "    \n",
    "# Get the data\n",
    "    RawEvents=LoadEventNexus(InputFile)\n",
    "    RawEvents=Rebin(RawEvents, \"2e4, 1., 6e4\", PreserveEvents=True) # so that we can plot things in more that one time bin\n",
    "    \n",
    "# Remove the proton flash    \n",
    "    NoProtonFlash=RemovePromptPulse(RawEvents, Width=300,Frequency=60.0)   \n",
    "    \n",
    "# Get the proton charge per pulse and absolute time for each pulse.\n",
    "    pc_values = NoProtonFlash.getRun()['proton_charge'].value\n",
    "    pc_times  = NoProtonFlash.getRun()['proton_charge'].times    \n",
    "    \n",
    "# Filter flipper states\n",
    "    (ListOfFilteredCrossSections,\n",
    "     DictOfFilteredCrossSections)=filter_cross_sections(NoProtonFlash)\n",
    "    # Note: Since the list and the dictionary point to the same set of \n",
    "    #       Mantid workspaces, changing one will change the other.\n",
    "    \n",
    "# Calculate mean proton charge over entire measurement in order to filter out outliers\n",
    "   \n",
    "    if True:   # Choose your way to calculate the mean\n",
    "        #True.  = > Use numpy\n",
    "        # Exclude pc values corresponding to zero which occur often if not running at 60Hz, or not running\n",
    "        _index = np.argwhere(pc_values>0)\n",
    "        mean_pc = np.mean(pc_values[_index])\n",
    "        rms_width = np.std(pc_values[_index])\n",
    "        \n",
    "    else: # False => Use method below\n",
    "        charge_sum = np.double(0.)\n",
    "        charge2_sum = np.double(0.)\n",
    "        n_sum = np.int32(0)\n",
    "        for K in DictOfFilteredCrossSections.keys(): # As long as we don't  \n",
    "                                                     # care about what order   \n",
    "                                                     # we take the cross sections\n",
    "                                                     # in we can do this.\n",
    "            for x in range(256*304):\n",
    "                f=DictOfFilteredCrossSections[K].getSpectrum(x) # spectrum for a single pixel vs. time\n",
    "                tofs=f.getTofs(); PulseTimes = f.getPulseTimes(); \n",
    "                for i in range(f.getNumberEvents()): \n",
    "                    t = mantid.kernel.DateAndTime(PulseTimes[i]).to_datetime64()\n",
    "                    _index = np.searchsorted(pc_times, t)\n",
    "                    charge = pc_values[_index]\n",
    "                    charge_sum = charge_sum + charge\n",
    "                    charge2_sum = charge2_sum + charge*charge\n",
    "                    n_sum = n_sum + 1\n",
    "        mean_pc = charge_sum/n_sum # mean per pulse\n",
    "        rms_width = np.sqrt((charge2_sum-2*mean_pc*charge_sum+n_sum*mean_pc*mean_pc)/(n_sum-1))\n",
    "    print('Mean proton charge: %.2f (%.2f)'%(mean_pc,rms_width))\n",
    "\n",
    "# Write event lists while excluding outliers based on proton current\n",
    "    n_sig = 4 # accept events for frames having proton charge within 4-sigma\n",
    "    for K in DictOfFilteredCrossSections.keys(): \n",
    "        OFile = open(OutputFile+'_%s.txt'%(K), 'w')\n",
    "        print('Writing: '+OutputFile+'_%s.txt'%(K))\n",
    "        OutList =[] ; OutStrings=[]\n",
    "        for x in range(256*304):\n",
    "            f=DictOfFilteredCrossSections[K].getSpectrum(x) # spectrum for a single pixel vs. time\n",
    "            tofs=f.getTofs(); PulseTimes = f.getPulseTimes(); \n",
    "            for i in range(f.getNumberEvents()): \n",
    "                t = mantid.kernel.DateAndTime(PulseTimes[i]).to_datetime64()\n",
    "                _index = np.searchsorted(pc_times, t)\n",
    "                charge = pc_values[_index]\n",
    "                dt64 = np.datetime64(pc_times[_index])\n",
    "# OutList contains n-events defined by absolute time of t0 in ns and string forms, tof (micro-s), pixel-id, proton charge\n",
    "# Here apply filter, only append if within 1-sigma of mean proton charge\n",
    "                if np.abs(charge-mean_pc) < n_sig/2*rms_width:        \n",
    "                    OutList.append((dt64.astype(datetime),tofs[i], x, charge))\n",
    "                    OutStrings.append(\"%s\\t%.10f\\t%d\\t%.10f\\n\"%(PulseTimes[i],\n",
    "                                   tofs[i], x, charge))    \n",
    "        OutStrings.sort()\n",
    "        for item in OutStrings: \n",
    "            OFile.write(item)\n",
    "        OFile.close()\n",
    "        OutList.sort()    \n",
    "        t0_time = np.zeros(len(OutList), dtype=np.uint64)\n",
    "        t0_time_string = []\n",
    "        tof = np.zeros(len(OutList), dtype=np.float32)\n",
    "        pixel_id = np.zeros(len(OutList), dtype=np.uint32)\n",
    "        pcharge = np.zeros(len(OutList), dtype=np.float32)\n",
    "        for i in range(len(OutList)):\n",
    "            x = OutList[i]\n",
    "            t0_time[i] = x[0]\n",
    "            t0_time_string.append(np.datetime64(x[0],'ns'))\n",
    "            tof[i] = x[1]\n",
    "            pixel_id[i] = x[2]\n",
    "            pcharge[i] = x[3]    \n",
    "        np.savez(OutputFile+'_%s.npz'%(K),t0_time,t0_time_string,tof,pixel_id,pcharge)\n",
    "\n",
    "# Write slow log data\n",
    "    RunInfo=RawEvents.getRun()\n",
    "    instrument = RawEvents.getInstrument()\n",
    "    source = instrument.getSource()\n",
    "    sample = instrument.getSample()\n",
    "    Parameters = instrument.getParameterNames()\n",
    "    Source_Sample_Distance = sample.getDistance(source) # m\n",
    "    Det=instrument.getDetector(int(256*304/2))  # distance from sample to center of detector\n",
    "    Sample_Detector_Center_Distance = Det.getDistance(sample) # m\n",
    "    pixel_to_coordinate = np.zeros((256*304,3), dtype=np.float32)\n",
    "    for i in range(256*304):\n",
    "        Det=instrument.getDetector(i)  # i is the detetector element index\n",
    "        PixelPos = Det.getPos()\n",
    "        pixel_to_coordinate[i,0]= Det.getDistance(sample) # m\n",
    "        pixel_to_coordinate[i,1]= np.arctan(float(PixelPos[0])/float(PixelPos[2])) # radians\n",
    "        pixel_to_coordinate[i,2]= np.arctan(float(PixelPos[1])/float(PixelPos[2])) # radians\n",
    "    OutStrings2 = []\n",
    "    OutStrings2.append('Source to sample distance: %s [m]\\n'%Source_Sample_Distance)\n",
    "    OutStrings2.append('Sample to PSD center distance: %s [m]\\n'%Sample_Detector_Center_Distance)\n",
    "\n",
    "    TemperatureLog= RunInfo.getLogData('BL4A:SE:Lakeshore:KRDG1')\n",
    "    OutStrings2.append('Mean temperature: %.2f(%.2f) [K]\\n'%(np.mean(TemperatureLog.value[:]),np.std(TemperatureLog.value[:])))\n",
    "\n",
    "    DANGLELog=RunInfo.getLogData('DANGLE')\n",
    "    OutStrings2.append('Detector angle: %.2f(%.2f) [degrees]\\n'%(np.mean(DANGLELog.value[:]),np.std(DANGLELog.value[:])))\n",
    "\n",
    "    DANGLE0Log=RunInfo.getLogData('DANGLE0')\n",
    "    OutStrings2.append('Detector offset angle: %.2f(%.2f) [degrees]\\n'%(np.mean(DANGLE0Log.value[:]),np.std(DANGLE0Log.value[:])))\n",
    "    \n",
    "    SANGLELog=RunInfo.getLogData('SANGLE')\n",
    "    OutStrings2.append('Sample angle: %.2f(%.2f) [degrees]\\n'%(np.mean(SANGLELog.value[:]),np.std(SANGLELog.value[:])))\n",
    "\n",
    "    C0Log= RunInfo.getLogData('BL4A:CS:ExpPlan:DirectPixel')\n",
    "    OutStrings2.append('Direct Beam Pixel: %s\\n'%np.mean(C0Log.value[:]))\n",
    "\n",
    "    ChopperFreqLog= RunInfo.getLogData('BL4A:Chop:Gbl:Speed:Req')\n",
    "    OutStrings2.append('Chopper Frequency: %s [Hz]\\n'%np.mean(ChopperFreqLog.value[:]))\n",
    "\n",
    "    LambdaBarLog= RunInfo.getLogData('BL4A:Chop:Gbl:Wavelength:Req')\n",
    "    OutStrings2.append('Mean wavelength: %s [Angstroms]\\n'%np.mean(LambdaBarLog.value[:]))\n",
    "\n",
    "    EMagLog= RunInfo.getLogData('BL4A:SE:Bruker:FieldSP')\n",
    "    OutStrings2.append('Electromagnet induction: %.4f (%.4f) [T]\\n'%(np.mean(EMagLog.value[:]),np.std(EMagLog.value[:])))\n",
    "\n",
    "    try:\n",
    "        MagHSPLog= RunInfo.getLogData('BL4A:SE:MagH:SP')\n",
    "        OutStrings2.append('MagH induction (set point): %.4f (%.4f) [T]\\n'%(np.mean(MagHSPLog.value[:]),np.std(MagHSPLog.value[:])))\n",
    "        MagHLog= RunInfo.getLogData('BL4A:SE:MagH:ReadField')\n",
    "        OutStrings2.append('MagH induction (actual): %.4f (%.4f) [T]\\n'%(np.mean(MagHLog.value[:]),np.std(MagHLog.value[:])))\n",
    "        MagH = True\n",
    "    \n",
    "    except RuntimeError:\n",
    "        print('No MagH process variable in nexus file.')\n",
    "        MagH = False # new S.E. not all files have this variable\n",
    "\n",
    "    OFile = open(OutputFile+'_log.txt', 'w')\n",
    "    print('Writing: '+OutputFile+'_log.txt')\n",
    "    for item in OutStrings2: \n",
    "        OFile.write(item)\n",
    "    OFile.close()\n",
    "\n",
    "    if MagH:\n",
    "        np.savez(OutputFile+'_log.npz',pixel_to_coordinate,\n",
    "                 Source_Sample_Distance,\n",
    "                 Sample_Detector_Center_Distance,\n",
    "                 TemperatureLog.times,TemperatureLog.value,\n",
    "                 DANGLELog.times,DANGLELog.value,\n",
    "                 DANGLE0Log.times,DANGLE0Log.value,\n",
    "                 SANGLELog.times,SANGLELog.value,\n",
    "                 C0Log.times,C0Log.value,\n",
    "                 ChopperFreqLog.times,ChopperFreqLog.value,\n",
    "                 LambdaBarLog.times,LambdaBarLog.value,\n",
    "                 EMagLog.times,EMagLog.value,\n",
    "                 MagHSPLog.times,MagHSPLog.value,\n",
    "                 MagHLog.times,MagHLog.value)\n",
    "    else:\n",
    "        np.savez(OutputFile+'_log.npz',pixel_to_coordinate,\n",
    "                 Source_Sample_Distance,\n",
    "                 Sample_Detector_Center_Distance,\n",
    "                 TemperatureLog.times,TemperatureLog.value,\n",
    "                 DANGLELog.times,DANGLELog.value,\n",
    "                 DANGLE0Log.times,DANGLE0Log.value,\n",
    "                 SANGLELog.times,SANGLELog.value,\n",
    "                 C0Log.times,C0Log.value,\n",
    "                 ChopperFreqLog.times,ChopperFreqLog.value,\n",
    "                 LambdaBarLog.times,LambdaBarLog.value,\n",
    "                 EMagLog.times,EMagLog.value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python2-mantid-nightly at jnrk-sns-analysis",
   "language": "python",
   "name": "jnrk-sns-analysis-python2-mantid-nightly"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
